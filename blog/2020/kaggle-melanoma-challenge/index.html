<!DOCTYPE html> <html> <head> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Getting Started with Kaggle Competitions: Melanoma Classification Challenge | Jay Gala</title> <meta name="author" content="Jay Gala"/> <meta name="description" content="This blog gives a gentle introduction for beginners on getting started with Kaggle competitions."/> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="preconnect" href="https://fonts.googleapis.com"> <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin> <link href="https://fonts.googleapis.com/css2?family=Space+Grotesk:wght@300..700&display=swap" rel="stylesheet"> <link href="https://fonts.googleapis.com/css2?family=Inconsolata:wght@200..900&display=swap" rel="stylesheet"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light"/> <link rel="shortcut icon" href="/assets/img/favicon.ico"/> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://jaygala24.github.io/blog/2020/kaggle-melanoma-challenge/"> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src="/assets/js/distillpub/template.v2.js"></script> <script src="/assets/js/distillpub/transforms.v2.js"></script> <script src="/assets/js/distillpub/overrides.js"></script> <style type="text/css">@media(min-width:576px){.output-plot img{display:block;margin-left:auto;margin-right:auto;width:50%}}.citations{display:none}</style> </head> <d-front-matter> <script async type="text/json">{
      "title": "Getting Started with Kaggle Competitions: Melanoma Classification Challenge",
      "description": "This blog gives a gentle introduction for beginners on getting started with Kaggle competitions.",
      "published": "December 2, 2020",
      "authors": [
        {
          "author": "Jay Gala",
          "authorURL": "https://jaygala24.github.io",
          "affiliations": [
            {
              "name": "University of Mumbai",
              "url": ""
            }
          ]
        },
        {
          "author": "Pranjal Chitale",
          "authorURL": "https://github.com/PranjalChitale",
          "affiliations": [
            {
              "name": "University of Mumbai",
              "url": ""
            }
          ]
        }
        
      ],
      "katex": {
        "delimiters": [
          {
            "left": "$",
            "right": "$",
            "display": false
          },
          {
            "left": "$$",
            "right": "$$",
            "display": true
          }
        ]
      }
    }</script> </d-front-matter> <body class="fixed-top-nav"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <div class="navbar-brand social"> <a href="mailto:%6A%61%79%67%61%6C%61%32%34@%67%6D%61%69%6C.%63%6F%6D" title="email"><i class="fas fa-envelope"></i></a> <a href="https://scholar.google.com/citations?user=lNn2qGoAAAAJ" title="Google Scholar" target="_blank" rel="noopener noreferrer"><i class="ai ai-google-scholar"></i></a> <a href="https://www.semanticscholar.org/author/1992915388" title="Semantic Scholar" target="_blank" rel="noopener noreferrer"><i class="ai ai-semantic-scholar"></i></a> <a href="https://github.com/jaygala24" title="GitHub" target="_blank" rel="noopener noreferrer"><i class="fab fa-github"></i></a> <a href="https://www.linkedin.com/in/jaygala24" title="LinkedIn" target="_blank" rel="noopener noreferrer"><i class="fab fa-linkedin"></i></a> <a href="https://twitter.com/jaygala24" title="Twitter" target="_blank" rel="noopener noreferrer"><i class="fab fa-twitter"></i></a> </div> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/talks/">talks</a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/cv.pdf">cv</a> </li> </ul> </div> </div> </nav> </header> <div class="post distill"> <d-title> <h1>Getting Started with Kaggle Competitions: Melanoma Classification Challenge</h1> <p>This blog gives a gentle introduction for beginners on getting started with Kaggle competitions.</p> </d-title> <d-byline></d-byline> <d-article> <d-contents> <nav class="l-text figcaption"> <h3>Contents</h3> <div><a href="#download-data">Download Data</a></div> <div><a href="#what-is-melanoma">What is Melanoma?</a></div> <div><a href="#objective">Objective</a></div> <div><a href="#about-the-dataset">About the Dataset</a></div> <div><a href="#evaluation-metrics">Evaluation Metrics</a></div> <div><a href="#losses">Losses</a></div> <div><a href="#network">Network</a></div> <ul> <li><a href="#efficientnet">EfficientNet</a></li> <li><a href="#squeeze-and-excitation-networks">Squeeze and Excitation Networks</a></li> </ul> <div><a href="#training-and-prediction">Training and Prediction</a></div> <div><a href="#results">Results</a></div> <div><a href="#future-resources">Future Resources</a></div> <div><a href="#references">References</a></div> </nav> </d-contents> <p>ðŸ“Œ Note: The authors of this blog post jointly participated in the Kaggle competition as a team.</p> <p>This post assumes that you are acquainted with the basic skills of working with <a href="https://pytorch.org/" target="_blank" rel="noopener noreferrer">PyTorch</a>. If you are new to PyTorch, we would highly encourage you to go through <a href="https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html" target="_blank" rel="noopener noreferrer">Deep Leaning With PyTorch: A 60 Minute Blitz by PyTorch</a>. Itâ€™s a great place for beginners to get your hands dirty.</p> <h2 id="download-data">Download Data</h2> <p>Here we will be using the preprocessed images by <a href="https://www.kaggle.com/arroqc/siic-isic-224x224-images" target="_blank" rel="noopener noreferrer">Arnaud Roussel</a> due to storage limitations on Google Colab.</p> <p>Now letâ€™s download the preprocessed image dataset using the Kaggle API. Remember to add your <code class="language-plaintext highlighter-rouge">USERNAME</code> and <code class="language-plaintext highlighter-rouge">API_KEY</code> in the code block below.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">kaggle</span> <span class="o">-</span><span class="n">q</span>
<span class="err">!</span><span class="n">mkdir</span> <span class="o">/</span><span class="n">root</span><span class="o">/</span><span class="p">.</span><span class="n">kaggle</span>
<span class="err">!</span><span class="n">echo</span> <span class="sh">'</span><span class="s">{</span><span class="sh">"</span><span class="s">username</span><span class="sh">"</span><span class="s">:</span><span class="sh">"</span><span class="s">YOUR_USERNAME</span><span class="sh">"</span><span class="s">,</span><span class="sh">"</span><span class="s">key</span><span class="sh">"</span><span class="s">:</span><span class="sh">"</span><span class="s">YOUR_API_KEY</span><span class="sh">"</span><span class="s">}</span><span class="sh">'</span> <span class="o">&gt;</span> <span class="o">/</span><span class="n">root</span><span class="o">/</span><span class="p">.</span><span class="n">kaggle</span><span class="o">/</span><span class="n">kaggle</span><span class="p">.</span><span class="n">json</span>
<span class="err">!</span><span class="n">chmod</span> <span class="mi">600</span> <span class="o">/</span><span class="n">root</span><span class="o">/</span><span class="p">.</span><span class="n">kaggle</span><span class="o">/</span><span class="n">kaggle</span><span class="p">.</span><span class="n">json</span>
<span class="err">!</span><span class="n">kaggle</span> <span class="n">datasets</span> <span class="n">download</span> <span class="o">-</span><span class="n">d</span> <span class="n">arroqc</span><span class="o">/</span><span class="n">siic</span><span class="o">-</span><span class="n">isic</span><span class="o">-</span><span class="mi">224</span><span class="n">x224</span><span class="o">-</span><span class="n">images</span>
<span class="err">!</span><span class="n">mkdir</span> <span class="o">/</span><span class="n">content</span><span class="o">/</span><span class="n">siic</span><span class="o">-</span><span class="n">isic</span><span class="o">-</span><span class="mi">224</span><span class="n">x224</span><span class="o">-</span><span class="n">images</span>
<span class="err">!</span><span class="n">unzip</span> <span class="o">-</span><span class="n">q</span> <span class="o">/</span><span class="n">content</span><span class="o">/</span><span class="n">siic</span><span class="o">-</span><span class="n">isic</span><span class="o">-</span><span class="mi">224</span><span class="n">x224</span><span class="o">-</span><span class="n">images</span><span class="p">.</span><span class="nb">zip</span> <span class="o">-</span><span class="n">d</span> <span class="o">/</span><span class="n">content</span><span class="o">/</span><span class="n">siic</span><span class="o">-</span><span class="n">isic</span><span class="o">-</span><span class="mi">224</span><span class="n">x224</span><span class="o">-</span><span class="n">images</span>
</code></pre></div></div> <p>Download the csv files from the <a href="https://www.kaggle.com/c/siim-isic-melanoma-classification/data" target="_blank" rel="noopener noreferrer">competition page</a> and place this files in the <code class="language-plaintext highlighter-rouge">content</code> directory.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="err">!</span><span class="n">python3</span> <span class="o">-</span><span class="n">m</span> <span class="n">pip</span> <span class="n">install</span> <span class="o">--</span><span class="n">upgrade</span> <span class="n">pip</span> <span class="o">-</span><span class="n">q</span>
<span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">efficientnet_pytorch</span> <span class="n">pretrainedmodels</span> <span class="o">-</span><span class="n">q</span>
</code></pre></div></div> <h2 id="what-is-melanoma">What is Melanoma?</h2> <p>Malignant Melanoma is a type of skin cancer that develops from pigment-producing cells known as melanocytes.</p> <p>The skin cells found in the upper layer of the skin are termed as Melanocytes. These produce a pigment Melanin, which is the pigment that is responsible for skin color. Exposure to UV radiation from the sun or tanning beds causes skin damage as it triggers these melanocytes to increase the secretion of Melanin.</p> <p>Melanoma occurs when there is DNA damage caused by burning or tanning due to UV exposure, triggering mutations in the melanocytes leading to unrestricted cellular growth.</p> <h2 id="objective">Objective</h2> <p>The objective of this competition is to identify melanoma in images of skin lesions. In particular, we need to use images within the same patient and determine which are likely to represent a melanoma. Using patient-level contextual information may help the development of image analysis tools, which could better support clinical dermatologists.</p> <p>Melanoma is a deadly disease, but if detected at an early stage, most melanomas can be cured with minor surgery.</p> <p>This competition is aimed at building a Classification Model that can predict whether the onset of malignant Melanoma from lesion images.</p> <p>In short, we need to create a classification model that is capable of distinguishing whether the lesion in the image is benign (class 0) or malignant (class 1).</p> <p>This will be very helpful to detect the early signs so that further medical attention can be made available to the patient.</p> <p>Now letâ€™s import the necessary packages below.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="kn">import</span> <span class="n">os</span>
<span class="kn">from</span> <span class="n">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">from</span> <span class="n">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">StratifiedKFold</span>
<span class="kn">from</span> <span class="n">sklearn.metrics</span> <span class="kn">import</span> <span class="n">roc_auc_score</span>
<span class="kn">import</span> <span class="n">torch</span>
<span class="kn">import</span> <span class="n">torch.nn</span> <span class="k">as</span> <span class="n">nn</span>
<span class="kn">import</span> <span class="n">torch.nn.functional</span> <span class="k">as</span> <span class="n">F</span>
<span class="kn">import</span> <span class="n">torchvision.transforms</span> <span class="k">as</span> <span class="n">transforms</span>
<span class="kn">import</span> <span class="n">albumentations</span>
<span class="kn">import</span> <span class="n">pretrainedmodels</span>
<span class="kn">from</span> <span class="n">efficientnet_pytorch</span> <span class="kn">import</span> <span class="n">EfficientNet</span>
<span class="kn">from</span> <span class="n">PIL</span> <span class="kn">import</span> <span class="n">Image</span>
</code></pre></div></div> <p>Now, we select the device on which our network will run. Neural style transfer algorithm runs faster on GPU so check if GPU is available using <code class="language-plaintext highlighter-rouge">torch.cuda.is_available()</code>.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># device configuration
</span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">device</span><span class="p">(</span><span class="sh">'</span><span class="s">cuda</span><span class="sh">'</span> <span class="k">if</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="nf">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="sh">'</span><span class="s">cpu</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div> <h2 id="about-the-dataset">About the Dataset</h2> <p>The dataset consists of images and metadata, which are described as follows:</p> <ul> <li>Images: DICOM, JPEG, TFRecord formats</li> <li>Metadata: image_name, patient_id, sex, age_approx, anatom_site_general_challenge, diagnosis, benign_malignant, target</li> </ul> <p>Letâ€™s take a look at the dataset.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train_images_path</span> <span class="o">=</span> <span class="sh">'</span><span class="s">./siic-isic-224x224-images/train/</span><span class="sh">'</span>
<span class="n">test_images_path</span> <span class="o">=</span> <span class="sh">'</span><span class="s">./siic-isic-224x224-images/test/</span><span class="sh">'</span>
<span class="n">train_df_path</span> <span class="o">=</span> <span class="sh">'</span><span class="s">./train.csv</span><span class="sh">'</span>
<span class="n">test_df_path</span> <span class="o">=</span> <span class="sh">'</span><span class="s">./test.csv</span><span class="sh">'</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train_df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="n">train_df_path</span><span class="p">)</span>
<span class="n">test_df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="n">test_df_path</span><span class="p">)</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train_df</span><span class="p">.</span><span class="nf">head</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
</code></pre></div></div> <table> <thead> <tr> <th>Â </th> <th>image_name</th> <th>patient_id</th> <th>sex</th> <th>age_approx</th> <th>anatom_site_general_challenge</th> <th>diagnosis</th> <th>benign_malignant</th> <th>target</th> </tr> </thead> <tbody> <tr> <td>0</td> <td>ISIC_2637011</td> <td>IP_7279968</td> <td>male</td> <td>45.0</td> <td>head/neck</td> <td>unknown</td> <td>benign</td> <td>0</td> </tr> <tr> <td>1</td> <td>ISIC_0015719</td> <td>IP_3075186</td> <td>female</td> <td>45.0</td> <td>upper extremity</td> <td>unknown</td> <td>benign</td> <td>0</td> </tr> <tr> <td>2</td> <td>ISIC_0052212</td> <td>IP_2842074</td> <td>female</td> <td>50.0</td> <td>lower extremity</td> <td>nevus</td> <td>benign</td> <td>0</td> </tr> <tr> <td>3</td> <td>ISIC_0068279</td> <td>IP_6890425</td> <td>female</td> <td>45.0</td> <td>head/neck</td> <td>unknown</td> <td>benign</td> <td>0</td> </tr> <tr> <td>4</td> <td>ISIC_0074268</td> <td>IP_8723313</td> <td>female</td> <td>55.0</td> <td>upper extremity</td> <td>unknown</td> <td>benign</td> <td>0</td> </tr> </tbody> </table> <p>Letâ€™s take a look at the number of samples in the train and test set.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Train data shape: </span><span class="si">{</span><span class="n">train_df</span><span class="p">.</span><span class="n">shape</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Test data shape: </span><span class="si">{</span><span class="n">test_df</span><span class="p">.</span><span class="n">shape</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Train data shape: (33126, 8)
Test data shape: (10982, 6)
</code></pre></div></div> <p>Letâ€™s take a look at the missing value count for each attribute.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train_df</span><span class="p">.</span><span class="nf">isnull</span><span class="p">().</span><span class="nf">sum</span><span class="p">()</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>image_name                         0
patient_id                         0
sex                               65
age_approx                        68
anatom_site_general_challenge    527
diagnosis                          0
benign_malignant                   0
target                             0
dtype: int64
</code></pre></div></div> <p>We observe that the metadata contains several missing values. Imputation strategies like replacing with mean or k-nearest neighbors could be used. However, we did not go ahead with the same as we feel that it might induce some bias and negatively influence the classifier.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># prepare the data: (training_images, labels)
</span><span class="n">train_df</span><span class="p">[</span><span class="sh">'</span><span class="s">image_path</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">train_df</span><span class="p">[</span><span class="sh">'</span><span class="s">image_name</span><span class="sh">'</span><span class="p">].</span><span class="nf">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">img_name</span><span class="p">:</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="nf">join</span><span class="p">(</span><span class="n">train_images_path</span><span class="p">,</span> <span class="n">img_name</span> <span class="o">+</span> <span class="sh">'</span><span class="s">.png</span><span class="sh">'</span><span class="p">)).</span><span class="n">values</span>
<span class="n">test_df</span><span class="p">[</span><span class="sh">'</span><span class="s">image_path</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">test_df</span><span class="p">[</span><span class="sh">'</span><span class="s">image_name</span><span class="sh">'</span><span class="p">].</span><span class="nf">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">img_name</span><span class="p">:</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="nf">join</span><span class="p">(</span><span class="n">test_images_path</span><span class="p">,</span> <span class="n">img_name</span> <span class="o">+</span> <span class="sh">'</span><span class="s">.png</span><span class="sh">'</span><span class="p">)).</span><span class="n">values</span>
<span class="n">test_df</span><span class="p">.</span><span class="nf">to_csv</span><span class="p">(</span><span class="sh">'</span><span class="s">test.csv</span><span class="sh">'</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</code></pre></div></div> <p>Letâ€™s take a look at the sample images of both classes.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">plot_images</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">nrows</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">data</span><span class="p">[</span><span class="sh">'</span><span class="s">target</span><span class="sh">'</span><span class="p">]</span> <span class="o">==</span> <span class="n">target</span><span class="p">].</span><span class="nf">sample</span><span class="p">(</span><span class="n">nrows</span> <span class="o">*</span> <span class="n">ncols</span><span class="p">)[</span><span class="sh">'</span><span class="s">image_path</span><span class="sh">'</span><span class="p">]</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="n">nrows</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="n">ncols</span> <span class="o">*</span> <span class="mi">2</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">image_path</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
        <span class="n">image</span> <span class="o">=</span> <span class="n">Image</span><span class="p">.</span><span class="nf">open</span><span class="p">(</span><span class="n">image_path</span><span class="p">)</span>
        <span class="n">plt</span><span class="p">.</span><span class="nf">subplot</span><span class="p">(</span><span class="n">nrows</span><span class="p">,</span> <span class="n">ncols</span><span class="p">,</span> <span class="n">idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">plt</span><span class="p">.</span><span class="nf">imshow</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
        <span class="n">plt</span><span class="p">.</span><span class="nf">axis</span><span class="p">(</span><span class="sh">'</span><span class="s">off</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">();</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># benign samples
</span><span class="nf">plot_images</span><span class="p">(</span><span class="n">train_df</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</code></pre></div></div> <div class="output-plot"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/kaggle_melanoma_challenge/benign_samples-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/kaggle_melanoma_challenge/benign_samples-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/kaggle_melanoma_challenge/benign_samples-1400.webp"></source> <img src="/assets/img/kaggle_melanoma_challenge/benign_samples.jpeg" class="img-fluid rounded" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># malign samples
</span><span class="nf">plot_images</span><span class="p">(</span><span class="n">train_df</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></div> <div class="output-plot"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/kaggle_melanoma_challenge/malign_samples-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/kaggle_melanoma_challenge/malign_samples-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/kaggle_melanoma_challenge/malign_samples-1400.webp"></source> <img src="/assets/img/kaggle_melanoma_challenge/malign_samples.jpeg" class="img-fluid rounded" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <p>Letâ€™s take a look at the distribution of target class label:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">% benign: {:.4f}</span><span class="sh">'</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="nf">sum</span><span class="p">(</span><span class="n">train_df</span><span class="p">[</span><span class="sh">'</span><span class="s">target</span><span class="sh">'</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="o">/</span> <span class="nf">len</span><span class="p">(</span><span class="n">train_df</span><span class="p">)))</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">% malign: {:.4f}</span><span class="sh">'</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="nf">sum</span><span class="p">(</span><span class="n">train_df</span><span class="p">[</span><span class="sh">'</span><span class="s">target</span><span class="sh">'</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="nf">len</span><span class="p">(</span><span class="n">train_df</span><span class="p">)))</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>% benign: 0.9824
% malign: 0.0176
</code></pre></div></div> <p>Upon analyzing the dataset, it is observed that</p> <ul> <li>Target class distribution is not balanced, and more samples belong to the benign (majority) class than the malign (minority) class</li> <li>If we directly split the dataset into a proportion of say 80:20, then it is possible that the split may not be representative of the actual dataset having the same ratio of the class labels</li> <li>This will induce a bias towards predicting the benign class label and thus significantly impact the performance of the classifier</li> </ul> <p>In order to avoid the bias due to an imbalanced dataset and ensure the same distribution of the class labels, we employ the stratified k-fold cross-validation to obtain the same distribution of the class labels in each fold. This cross-validation ensures that we are able to make predictions on all of the data using k different models.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># create folds
</span><span class="n">n_splits</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">train_df</span><span class="p">[</span><span class="sh">'</span><span class="s">kfold</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
<span class="n">train_df</span> <span class="o">=</span> <span class="n">train_df</span><span class="p">.</span><span class="nf">sample</span><span class="p">(</span><span class="n">frac</span><span class="o">=</span><span class="mi">1</span><span class="p">).</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">train_df_labels</span> <span class="o">=</span> <span class="n">train_df</span><span class="p">.</span><span class="n">target</span><span class="p">.</span><span class="n">values</span>

<span class="n">skf</span> <span class="o">=</span> <span class="nc">StratifiedKFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="n">n_splits</span><span class="p">)</span>

<span class="k">for</span> <span class="n">fold_idx</span><span class="p">,</span> <span class="p">(</span><span class="n">train_idx</span><span class="p">,</span> <span class="n">valid_idx</span><span class="p">)</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">skf</span><span class="p">.</span><span class="nf">split</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">train_df</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">train_df_labels</span><span class="p">)):</span>
    <span class="n">train_df</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">valid_idx</span><span class="p">,</span> <span class="sh">'</span><span class="s">kfold</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">fold_idx</span>

<span class="n">train_df</span><span class="p">.</span><span class="nf">to_csv</span><span class="p">(</span><span class="sh">'</span><span class="s">train_folds.csv</span><span class="sh">'</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</code></pre></div></div> <p>Now letâ€™s create a custom data loader to load the data from the specified image paths; it is also capable of performing transformations(if required), directly at the loading stage, so we donâ€™t need to worry about the transformations at later stages.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">MelanomaDataset</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">image_paths</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">resize</span><span class="p">,</span> <span class="n">augmentations</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Initialize the Melanoma Dataset Class
        </span><span class="sh">"""</span>
        <span class="n">self</span><span class="p">.</span><span class="n">image_paths</span> <span class="o">=</span> <span class="n">image_paths</span>
        <span class="n">self</span><span class="p">.</span><span class="n">targets</span> <span class="o">=</span> <span class="n">targets</span>
        <span class="n">self</span><span class="p">.</span><span class="n">resize</span> <span class="o">=</span> <span class="n">resize</span>
        <span class="n">self</span><span class="p">.</span><span class="n">augmentations</span> <span class="o">=</span> <span class="n">augmentations</span>
    
    <span class="k">def</span> <span class="nf">__getitem__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Returns the data instance from specified index location
        </span><span class="sh">"""</span>
        <span class="n">image_path</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">image_paths</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>
        <span class="n">target</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">targets</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>
        
        <span class="c1"># open the image using PIL
</span>        <span class="n">image</span> <span class="o">=</span> <span class="n">Image</span><span class="p">.</span><span class="nf">open</span><span class="p">(</span><span class="n">image_path</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">resize</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">image</span> <span class="o">=</span> <span class="n">image</span><span class="p">.</span><span class="nf">resize</span><span class="p">(</span>
                <span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">resize</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">self</span><span class="p">.</span><span class="n">resize</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">resample</span><span class="o">=</span><span class="n">Image</span><span class="p">.</span><span class="n">BILINEAR</span>
            <span class="p">)</span>
        
        <span class="n">image</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>

        <span class="c1"># perform the augmentations if any
</span>        <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">augmentations</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">augmented</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">augmentations</span><span class="p">(</span><span class="n">image</span><span class="o">=</span><span class="n">image</span><span class="p">)</span>
            <span class="n">image</span> <span class="o">=</span> <span class="n">augmented</span><span class="p">[</span><span class="sh">'</span><span class="s">image</span><span class="sh">'</span><span class="p">]</span>
        
        <span class="c1"># make the channel first
</span>        <span class="n">image</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">transpose</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)).</span><span class="nf">astype</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="p">{</span>
            <span class="sh">'</span><span class="s">image</span><span class="sh">'</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">image</span><span class="p">),</span>
            <span class="sh">'</span><span class="s">target</span><span class="sh">'</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">target</span><span class="p">)</span>
        <span class="p">}</span>

    <span class="k">def</span> <span class="nf">__len__</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Returns the number of examples / instances
        </span><span class="sh">"""</span>
        <span class="k">return</span> <span class="nf">len</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">image_paths</span><span class="p">)</span>
</code></pre></div></div> <h2 id="evaluation-metrics">Evaluation Metrics</h2> <p>The area under the ROC curve (AUC) was used as an evaluation metric for the problem due to an imbalanced dataset. A ROC curve (receiver operating characteristic curve) is a graph showing the performance of a classifier at various classification thresholds. It is a measure of how well the model is capable of distinguishing between the different classes. This curve plots two parameters:</p> <ul> <li> <strong>True Positive Rate (TPR)</strong> is a synonym for recall and is therefore defined as follows:</li> </ul> \[{TPR = \frac{TP}{TP + FN}}\] <ul> <li> <strong>False Positive Rate (FPR)</strong> is defined as follows:</li> </ul> \[{FPR = \frac{FP}{FP + TN}}\] <p>AUC is a measure of the area underneath the entire ROC curve. It represents the degree of separability. It ranges in value from 0 to 1. The higher the AUC, the better the model is at distinguishing classes.</p> <p>For more details, please refer to the <a href="https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc" target="_blank" rel="noopener noreferrer">Classification: ROC Curve and AUC</a> by Googleâ€™s Machine Learning Crash Course.</p> <h2 id="losses">Losses</h2> <p>We use the Binary Cross Entropy (BCE) loss for the problem since here we need to classify the images into classes: benign or malignant. The formula of the BCE loss is as given below:</p> \[L = -\frac{1}{N}\sum_{i=1}^N{(y_i\log(p_i) + (1 - y_i)\log(1 - p_i))}\] <p>where $y_i$ is the class label (0 for benign and 1 for malign) and $p_i$ is the predicted probability of the image being malign for the $i^{th}$ sample</p> <p>We will use the <code class="language-plaintext highlighter-rouge">nn.BCEWithLogitsLoss</code> directly from the PyTorchâ€™s <code class="language-plaintext highlighter-rouge">nn</code> module.</p> <p>Another loss that we try for the problem is the Focal loss, an extension of BCE loss that tries to handle class imbalance by penalizing the misclassified examples. It is expressed as follows:</p> \[L = -\alpha_t(1 - p_t)^\gamma\log(p_t\] \[\alpha_t= \left\{\begin{matrix} \alpha &amp; if \; y = 1\\ 1 - \alpha &amp; otherwise \end{matrix}\right.\] <p>where $\gamma$ is a prefixed positive scalar value and $\alpha$ is a prefixed value between 0 and 1 to balance the positive labeled samples and negative labeled samples.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">FocalLoss</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Initialize the Focal Loss Class
        </span><span class="sh">"""</span>
        <span class="nf">super</span><span class="p">(</span><span class="n">FocalLoss</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>
        <span class="n">self</span><span class="p">.</span><span class="n">gamma</span> <span class="o">=</span> <span class="n">gamma</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">predictions</span><span class="p">,</span> <span class="n">targets</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Calculates the Focal Loss
        </span><span class="sh">"""</span>
        <span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">BCEWithLogitsLoss</span><span class="p">()</span>
        
        <span class="n">logits</span> <span class="o">=</span> <span class="nf">criterion</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">targets</span><span class="p">.</span><span class="nf">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">).</span><span class="nf">type_as</span><span class="p">(</span><span class="n">predictions</span><span class="p">))</span>
        <span class="n">pt</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">exp</span><span class="p">(</span><span class="o">-</span><span class="n">logits</span><span class="p">)</span>
        
        <span class="n">focal_loss</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">alpha</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">pt</span><span class="p">)</span> <span class="o">**</span> <span class="n">self</span><span class="p">.</span><span class="n">gamma</span> <span class="o">*</span> <span class="n">logits</span>
        
        <span class="k">return</span> <span class="n">torch</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">focal_loss</span><span class="p">)</span>
</code></pre></div></div> <h2 id="network">Network</h2> <p>Convolutional Neural Networks are very good at the task of image processing and classifications due to the following reasons:</p> <ul> <li>Require fewer parameters i.e. less complex than feed forward networks (FFNs) but are able to achieve as efficient or even better performance</li> <li>Able to identify the low-level features such as edges as well as high-level features such as objects or patterns</li> </ul> <p>Here we try the following two different network architectures:</p> <ul> <li>EfficientNet</li> <li>Squeeze and Excitation Network</li> </ul> <h3 id="efficientnet">EfficientNet</h3> <p>The EfficientNet architecture by Tan et al. focuses on scaling up the performance of traditional CNNs in terms of accuracy and at the same time, focuses on building a more computationally efficient architecture.</p> <p>How can CNNs be Scaled up?</p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/kaggle_melanoma_challenge/model_scaling_types-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/kaggle_melanoma_challenge/model_scaling_types-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/kaggle_melanoma_challenge/model_scaling_types-1400.webp"></source> <img src="/assets/img/kaggle_melanoma_challenge/model_scaling_types.jpeg" class="img-fluid rounded" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption"> Types of Model Scaling (<a href="https://arxiv.org/abs/1905.11946" target="_blank" rel="noopener noreferrer">image source</a>) </div> <p>Here compound scaling is the method proposed by Tan et al.</p> <p>Letâ€™s first analyze how traditional scaling works and why each type of scaling is necessary.</p> <ul> <li> <p><strong>Width Scaling (w)</strong>: The objective of using a wider network is that wider networks are more suited to capture more fine-grained features. This is typically used in shallow networks. But the problem is that if we make the network extremely wide, the performance of the network in terms of accuracy degrades. Therefore, we need an optimum width to maintain performance.</p> </li> <li> <p><strong>Depth Scaling (d)</strong>: Theoretically, deeper neural networks tend to capture more complex features and this makes the neural network generalize well to other tasks. But practically, if we go on making the network too deep, it will increase the computational complexity and such networks will require huge training times. Also very deep neural networks suffer from vanishing/exploding gradient problems. Therefore, we need an optimum depth to achieve good performance.</p> </li> <li> <p><strong>Resolution Scaling (r)</strong>: By intuition, we can consider that if we take a high-resolution image, it would yield more fine-grained features and thus would boost the performance. Though this is true to a certain extent, we cannot assume a linear relationship between these. This is because the accuracy gain diminishes very quickly. So to a certain extent, by resolution scaling, we can improve the performance of the network.</p> </li> </ul> <p>Based on their study, the authors have considered that all these 3 factors should be considered to a certain extent and a combined scaling technique must be incorporated.</p> <p>By intuition, if we are considering a high-resolution image, naturally, we have to increase the depth and the width of the network. To validate this intuition, the authors considered a fixed-width network (w) and varied the scaling factors r and d. It was observed that the accuracy improved when high-resolution images were passed through deeper neural networks.</p> <p>The authors have proposed a scaling technique which uses a compound coefficient $\phi$ in order to scale the width, depth and resolution of the network in a uniform fashion, which is expressed as follows:</p> \[{depth: d = \alpha^\phi}\] \[{width: w = \beta^\phi}\] \[{resolution: r = \gamma^\phi}\] \[such\ that\ \alpha\cdot\beta^2\cdot\gamma^2\approx2\ and\ \alpha,\ \beta,\ \gamma\ \geq 1\] <p>where $\phi$ is a use r-specified coefficient which can control how many resources are available and $\alpha$, $\beta$, $\gamma$ controls depth, width, image resolution, respectively.</p> <p>Firstly, for B0, the authors have fixed $\phi = 1$ and have assumed that twice more resources are available and have performed a small grid search for the other parameters. The optimal values which satisfy $\alpha\cdot\beta^2\cdot\gamma^2\approx2$, were found out to be $\alpha = 1.2$, $\beta = 1.1$ and $\gamma = 1.15$.</p> <p>Later, the authors kept these values of $\alpha$, $\beta$, $\gamma$ as constant and experimented with different values of $\phi$. The authors experiment with different values of $\phi$ to produce the variants EfficientNets B1-B7.</p> <p>For more details, please refer to the <a href="https://arxiv.org/abs/1905.11946" target="_blank" rel="noopener noreferrer">EfficientNet</a> paper.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">variant</span><span class="o">=</span><span class="sh">'</span><span class="s">efficientnet-b2</span><span class="sh">'</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Initializes pretrained EfficientNet model
        </span><span class="sh">"""</span>
        <span class="nf">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">base_model</span> <span class="o">=</span> <span class="n">EfficientNet</span><span class="p">.</span><span class="nf">from_pretrained</span><span class="p">(</span><span class="n">variant</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">base_model</span><span class="p">.</span><span class="n">_fc</span><span class="p">.</span><span class="n">in_features</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">image</span><span class="p">,</span> <span class="n">target</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Returns the result of forward propagation
        </span><span class="sh">"""</span>
        <span class="n">batch_size</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">image</span><span class="p">.</span><span class="n">shape</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">base_model</span><span class="p">.</span><span class="nf">extract_features</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>

        <span class="n">out</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">adaptive_avg_pool2d</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="mi">1</span><span class="p">).</span><span class="nf">view</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">fc</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        
        <span class="c1"># loss = nn.BCEWithLogitsLoss()(out, target.view(-1, 1).type_as(out))
</span>        <span class="n">loss</span> <span class="o">=</span> <span class="nc">FocalLoss</span><span class="p">()(</span><span class="n">out</span><span class="p">,</span> <span class="n">target</span><span class="p">.</span><span class="nf">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">).</span><span class="nf">type_as</span><span class="p">(</span><span class="n">out</span><span class="p">))</span>
        
        <span class="k">return</span> <span class="n">out</span><span class="p">,</span> <span class="n">loss</span>
    
<span class="n">model</span> <span class="o">=</span> <span class="nc">Net</span><span class="p">()</span>
</code></pre></div></div> <h3 id="squeeze-and-excitation-networks">Squeeze and Excitation Networks</h3> <p>Traditional convolutional neural networks (CNNs) use convolution operation which fuses information both spatially and channel-wise, but Jie Hu et al. proposed a novel architecture Squeeze and Excitation Networks (SENets) in the 2017 ImageNet challenge that focuses on the channel-wise information correlation. This network improved the results from the previous year by 25%.</p> <p>The basic intuition behind this approach was to adjust the feature map channel-wise by adding the parameters to each channel of a convolutional block. These parameters represent the relevance of each feature map to the information, much like we use attention in the recurrent neural networks (RNNs).</p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/kaggle_melanoma_challenge/squeeze_and_excitation_block-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/kaggle_melanoma_challenge/squeeze_and_excitation_block-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/kaggle_melanoma_challenge/squeeze_and_excitation_block-1400.webp"></source> <img src="/assets/img/kaggle_melanoma_challenge/squeeze_and_excitation_block.jpeg" class="img-fluid rounded" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption"> Squeeze and Excitation Block (<a href="https://arxiv.org/abs/1709.01507" target="_blank" rel="noopener noreferrer">image source</a>) </div> <p>The above figure represents the Squeeze-and-Excitation (SE) block where it performs a series of operations: squeeze and excitation, which allows the network to recalibrate the channel-wise information i.e. emphasize informative feature maps and suppresses less useful feature maps. The squeeze operation produces a channel descriptor expressive of the whole image by aggregating feature maps across the spatial dimensions using global average pooling. The excitation operation produces channel-wise relevance using the two fully-connected (FC) layers where the FC captures channel-wise dependencies. This block can be directly applied to the existing architectures such as ResNet, which is shown below.</p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/kaggle_melanoma_challenge/se_residual_block-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/kaggle_melanoma_challenge/se_residual_block-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/kaggle_melanoma_challenge/se_residual_block-1400.webp"></source> <img src="/assets/img/kaggle_melanoma_challenge/se_residual_block.jpeg" class="img-fluid rounded" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption"> Residual module (left) and SE ResNet module (right) (<a href="https://arxiv.org/abs/1709.01507" target="_blank" rel="noopener noreferrer">image source</a>) </div> <p>The computational overhead of the network depends on where you apply the SE block. There was a minor increase in the computational overhead, which is feasible compared to the performance boost achieved from the network. The authors applied the SE block at earlier layers to reduce the computation overhead since, at later layers, the number of parameters increases as the feature maps increase channel-wise.</p> <p>For more details, please refer to the <a href="https://arxiv.org/pdf/1709.01507.pdf" target="_blank" rel="noopener noreferrer">Squeeze-and-Excitation Networks</a> paper.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Initializes pretrained EfficientNet model
        </span><span class="sh">"""</span>
        <span class="nf">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">base_model</span> <span class="o">=</span> <span class="n">pretrainedmodels</span><span class="p">.</span><span class="nf">se_resnext50_32x4d</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="sh">'</span><span class="s">imagenet</span><span class="sh">'</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="mi">2048</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">image</span><span class="p">,</span> <span class="n">target</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Returns the result of forward propagation
        </span><span class="sh">"""</span>
        <span class="n">batch_size</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">image</span><span class="p">.</span><span class="n">shape</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">base_model</span><span class="p">.</span><span class="nf">features</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>

        <span class="n">out</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">adaptive_avg_pool2d</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="mi">1</span><span class="p">).</span><span class="nf">view</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">fc</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        
        <span class="c1"># loss = nn.BCEWithLogitsLoss()(out, target.view(-1, 1).type_as(out))
</span>        <span class="n">loss</span> <span class="o">=</span> <span class="nc">FocalLoss</span><span class="p">()(</span><span class="n">out</span><span class="p">,</span> <span class="n">target</span><span class="p">.</span><span class="nf">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">).</span><span class="nf">type_as</span><span class="p">(</span><span class="n">out</span><span class="p">))</span>
        
        <span class="k">return</span> <span class="n">out</span><span class="p">,</span> <span class="n">loss</span>
    
<span class="n">model</span> <span class="o">=</span> <span class="nc">Net</span><span class="p">()</span>
</code></pre></div></div> <h2 id="training-and-prediction">Training and Prediction</h2> <p>Here, we use early stopping and learning rate scheduler for training the model faster.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">fold</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    Train the model on a fold
    </span><span class="sh">"""</span>

    <span class="n">n_epochs</span> <span class="o">=</span> <span class="mi">50</span>
    <span class="n">train_bs</span> <span class="o">=</span> <span class="mi">32</span>
    <span class="n">valid_bs</span> <span class="o">=</span> <span class="mi">16</span>
    <span class="n">best_score</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="p">.</span><span class="n">Inf</span>
    <span class="n">es_patience</span> <span class="o">=</span> <span class="mi">5</span>
    <span class="n">patience</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">model_path</span> <span class="o">=</span> <span class="sh">'</span><span class="s">./model_fold_{:02d}.pth</span><span class="sh">'</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">fold</span><span class="p">)</span>

    <span class="n">train_folds_df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="n">train_folds_df_path</span><span class="p">)</span>
    <span class="n">train_df</span> <span class="o">=</span> <span class="n">train_folds_df</span><span class="p">[</span><span class="n">train_folds_df</span><span class="p">.</span><span class="n">kfold</span> <span class="o">!=</span> <span class="n">fold</span><span class="p">].</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">valid_df</span> <span class="o">=</span> <span class="n">train_folds_df</span><span class="p">[</span><span class="n">train_folds_df</span><span class="p">.</span><span class="n">kfold</span> <span class="o">==</span> <span class="n">fold</span><span class="p">].</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    
    <span class="n">train_images</span> <span class="o">=</span> <span class="n">train_df</span><span class="p">.</span><span class="n">image_path</span><span class="p">.</span><span class="n">values</span>
    <span class="n">train_targets</span> <span class="o">=</span> <span class="n">train_df</span><span class="p">.</span><span class="n">target</span><span class="p">.</span><span class="n">values</span>
    <span class="n">valid_images</span> <span class="o">=</span> <span class="n">valid_df</span><span class="p">.</span><span class="n">image_path</span><span class="p">.</span><span class="n">values</span>
    <span class="n">valid_targets</span> <span class="o">=</span> <span class="n">valid_df</span><span class="p">.</span><span class="n">target</span><span class="p">.</span><span class="n">values</span>

    <span class="n">model</span> <span class="o">=</span> <span class="nc">Net</span><span class="p">()</span>
    <span class="n">model</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

    <span class="n">mean</span> <span class="o">=</span> <span class="p">(</span><span class="mf">0.485</span><span class="p">,</span> <span class="mf">0.456</span><span class="p">,</span> <span class="mf">0.406</span><span class="p">)</span>
    <span class="n">std</span> <span class="o">=</span> <span class="p">(</span><span class="mf">0.229</span><span class="p">,</span> <span class="mf">0.224</span><span class="p">,</span> <span class="mf">0.225</span><span class="p">)</span>

    <span class="c1"># augmentations for train and validation images
</span>    <span class="n">train_aug</span> <span class="o">=</span> <span class="n">albumentations</span><span class="p">.</span><span class="nc">Compose</span><span class="p">([</span>
        <span class="n">albumentations</span><span class="p">.</span><span class="nc">Normalize</span><span class="p">(</span><span class="n">mean</span><span class="p">,</span> <span class="n">std</span><span class="p">,</span> <span class="n">max_pixel_value</span><span class="o">=</span><span class="mf">255.0</span><span class="p">,</span> <span class="n">always_apply</span><span class="o">=</span><span class="bp">True</span><span class="p">),</span>
        <span class="n">albumentations</span><span class="p">.</span><span class="nc">ShiftScaleRotate</span><span class="p">(</span><span class="n">shift_limit</span><span class="o">=</span><span class="mf">0.0625</span><span class="p">,</span> <span class="n">scale_limit</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">rotate_limit</span><span class="o">=</span><span class="mi">15</span><span class="p">),</span>
        <span class="n">albumentations</span><span class="p">.</span><span class="nc">Flip</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">),</span>
    <span class="p">])</span>

    <span class="n">valid_aug</span> <span class="o">=</span> <span class="n">albumentations</span><span class="p">.</span><span class="nc">Compose</span><span class="p">([</span>
        <span class="n">albumentations</span><span class="p">.</span><span class="nc">Normalize</span><span class="p">(</span><span class="n">mean</span><span class="p">,</span> <span class="n">std</span><span class="p">,</span> <span class="n">max_pixel_value</span><span class="o">=</span><span class="mf">255.0</span><span class="p">,</span> <span class="n">always_apply</span><span class="o">=</span><span class="bp">True</span><span class="p">),</span>
    <span class="p">])</span>

    <span class="c1"># creating dataset and dataloader for train and validation images
</span>    <span class="n">train_dataset</span> <span class="o">=</span> <span class="nc">MelanomaDataset</span><span class="p">(</span>
        <span class="n">image_paths</span><span class="o">=</span><span class="n">train_images</span><span class="p">,</span>
        <span class="n">targets</span><span class="o">=</span><span class="n">train_targets</span><span class="p">,</span>
        <span class="n">resize</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
        <span class="n">augmentations</span><span class="o">=</span><span class="n">train_aug</span>
    <span class="p">)</span>
    <span class="n">train_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="nc">DataLoader</span><span class="p">(</span>
        <span class="n">train_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">train_bs</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="mi">4</span>
    <span class="p">)</span>

    <span class="n">valid_dataset</span> <span class="o">=</span> <span class="nc">MelanomaDataset</span><span class="p">(</span>
        <span class="n">image_paths</span><span class="o">=</span><span class="n">valid_images</span><span class="p">,</span>
        <span class="n">targets</span><span class="o">=</span><span class="n">valid_targets</span><span class="p">,</span>
        <span class="n">resize</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
        <span class="n">augmentations</span><span class="o">=</span><span class="n">valid_aug</span>
    <span class="p">)</span>
    <span class="n">valid_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="nc">DataLoader</span><span class="p">(</span>
        <span class="n">valid_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">valid_bs</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="mi">4</span>
    <span class="p">)</span>

    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="nc">Adam</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">3e-4</span><span class="p">)</span>
    <span class="n">scheduler</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="n">lr_scheduler</span><span class="p">.</span><span class="nc">ReduceLROnPlateau</span><span class="p">(</span>
        <span class="n">optimizer</span><span class="p">,</span>
        <span class="n">patience</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
        <span class="n">threshold</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span>
        <span class="n">mode</span><span class="o">=</span><span class="sh">'</span><span class="s">max</span><span class="sh">'</span>
    <span class="p">)</span>

    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">n_epochs</span><span class="p">):</span>
        <span class="n">train_loss</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">valid_loss</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">train_steps</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">valid_steps</span> <span class="o">=</span> <span class="mi">0</span>
        
        <span class="c1"># model in train mode
</span>        <span class="n">model</span><span class="p">.</span><span class="nf">train</span><span class="p">()</span>

        <span class="n">tk0</span> <span class="o">=</span> <span class="nf">tqdm</span><span class="p">(</span><span class="n">train_loader</span><span class="p">,</span> <span class="n">total</span><span class="o">=</span><span class="nf">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">),</span> <span class="n">position</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">leave</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        
        <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">set_grad_enabled</span><span class="p">(</span><span class="bp">True</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">data</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">tk0</span><span class="p">):</span>

                <span class="c1"># load tensor to GPU
</span>                <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">data</span><span class="p">.</span><span class="nf">items</span><span class="p">():</span>
                    <span class="n">data</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
                
                <span class="c1"># forward pass
</span>                <span class="n">_</span><span class="p">,</span> <span class="n">loss</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="o">**</span><span class="n">data</span><span class="p">)</span>

                <span class="c1"># backward pass, optimize
</span>                <span class="n">optimizer</span><span class="p">.</span><span class="nf">zero_grad</span><span class="p">()</span>
                <span class="n">loss</span><span class="p">.</span><span class="nf">backward</span><span class="p">()</span>
                <span class="n">optimizer</span><span class="p">.</span><span class="nf">step</span><span class="p">()</span>

                <span class="n">train_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="p">.</span><span class="nf">item</span><span class="p">()</span>
                <span class="n">train_steps</span> <span class="o">+=</span> <span class="mi">1</span>

                <span class="c1"># update progress bar
</span>                <span class="n">tk0</span><span class="p">.</span><span class="nf">set_postfix</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="n">train_loss</span><span class="o">/</span><span class="n">train_steps</span><span class="p">)</span>

        <span class="n">tk0</span><span class="p">.</span><span class="nf">close</span><span class="p">()</span>

        <span class="c1"># model in eval mode
</span>        <span class="n">model</span><span class="p">.</span><span class="nf">eval</span><span class="p">()</span>
        <span class="n">val_predictions</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">((</span><span class="nf">len</span><span class="p">(</span><span class="n">valid_df</span><span class="p">),</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>

        <span class="n">tk0</span> <span class="o">=</span> <span class="nf">tqdm</span><span class="p">(</span><span class="n">valid_loader</span><span class="p">,</span> <span class="n">total</span><span class="o">=</span><span class="nf">len</span><span class="p">(</span><span class="n">valid_loader</span><span class="p">),</span> <span class="n">position</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">leave</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

        <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span>
            <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">data</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">tk0</span><span class="p">):</span>

                <span class="c1"># load tensor to GPU
</span>                <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">data</span><span class="p">.</span><span class="nf">items</span><span class="p">():</span>
                    <span class="n">data</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
                
                <span class="c1"># model prediction
</span>                <span class="n">batch_preds</span><span class="p">,</span> <span class="n">loss</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="o">**</span><span class="n">data</span><span class="p">)</span>

                <span class="n">start</span> <span class="o">=</span> <span class="n">idx</span> <span class="o">*</span> <span class="n">valid_bs</span>
                <span class="n">end</span> <span class="o">=</span> <span class="n">start</span> <span class="o">+</span> <span class="nf">len</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="sh">'</span><span class="s">image</span><span class="sh">'</span><span class="p">])</span>
                <span class="n">val_predictions</span><span class="p">[</span><span class="n">start</span><span class="p">:</span><span class="n">end</span><span class="p">]</span> <span class="o">=</span> <span class="n">batch_preds</span><span class="p">.</span><span class="nf">cpu</span><span class="p">()</span>
                
                <span class="n">valid_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="p">.</span><span class="nf">item</span><span class="p">()</span>
                <span class="n">valid_steps</span> <span class="o">+=</span> <span class="mi">1</span>
                
                <span class="c1"># update progress bar
</span>                <span class="n">tk0</span><span class="p">.</span><span class="nf">set_postfix</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="n">valid_loss</span><span class="o">/</span><span class="n">valid_steps</span><span class="p">)</span>
        
        <span class="n">tk0</span><span class="p">.</span><span class="nf">close</span><span class="p">()</span>

        <span class="c1"># schedule learning rate
</span>        <span class="n">auc</span> <span class="o">=</span> <span class="nf">roc_auc_score</span><span class="p">(</span><span class="n">valid_df</span><span class="p">.</span><span class="n">target</span><span class="p">.</span><span class="n">values</span><span class="p">,</span> <span class="n">val_predictions</span><span class="p">.</span><span class="nf">ravel</span><span class="p">())</span>
        <span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Epoch = {} , AUC = {}</span><span class="sh">'</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">auc</span><span class="p">))</span>
        <span class="n">scheduler</span><span class="p">.</span><span class="nf">step</span><span class="p">(</span><span class="n">auc</span><span class="p">)</span>

        <span class="c1"># early stopping
</span>        <span class="k">if</span> <span class="n">best_score</span> <span class="o">&lt;</span> <span class="n">auc</span><span class="p">:</span>
            <span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Validation score improved ({} -&gt; {}). Saving Model!</span><span class="sh">'</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">best_score</span><span class="p">,</span> <span class="n">auc</span><span class="p">))</span>
            <span class="n">best_score</span> <span class="o">=</span> <span class="n">auc</span>
            <span class="n">patience</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">torch</span><span class="p">.</span><span class="nf">save</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">state_dict</span><span class="p">(),</span> <span class="n">model_path</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">patience</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Early stopping counter: {} out of {}</span><span class="sh">'</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">patience</span><span class="p">,</span> <span class="n">es_patience</span><span class="p">))</span>
            <span class="k">if</span> <span class="n">patience</span> <span class="o">==</span> <span class="n">es_patience</span><span class="p">:</span>
                <span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Early stopping! Best AUC: {}</span><span class="sh">'</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">best_score</span><span class="p">))</span>
                <span class="k">break</span>

</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="n">fold</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    Model predictions on a fold
    </span><span class="sh">"""</span>

    <span class="n">test_bs</span> <span class="o">=</span> <span class="mi">16</span>
    <span class="n">model_path</span> <span class="o">=</span> <span class="sh">'</span><span class="s">./model_fold_{:02d}.pth</span><span class="sh">'</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">fold</span><span class="p">)</span>
    <span class="n">test_df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="n">test_df_path</span><span class="p">)</span>
    
    <span class="n">test_images</span> <span class="o">=</span> <span class="n">test_df</span><span class="p">.</span><span class="n">image_path</span><span class="p">.</span><span class="n">values</span>
    <span class="n">test_targets</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">test_images</span><span class="p">))</span>
    
    <span class="n">model</span> <span class="o">=</span> <span class="nc">Net</span><span class="p">()</span>
    <span class="n">model</span><span class="p">.</span><span class="nf">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="n">model_path</span><span class="p">))</span>
    <span class="n">model</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    
    <span class="n">mean</span> <span class="o">=</span> <span class="p">(</span><span class="mf">0.485</span><span class="p">,</span> <span class="mf">0.456</span><span class="p">,</span> <span class="mf">0.406</span><span class="p">)</span>
    <span class="n">std</span> <span class="o">=</span> <span class="p">(</span><span class="mf">0.229</span><span class="p">,</span> <span class="mf">0.224</span><span class="p">,</span> <span class="mf">0.225</span><span class="p">)</span>
    
    <span class="c1"># test augmentation on test images
</span>    <span class="n">test_aug</span> <span class="o">=</span> <span class="n">albumentations</span><span class="p">.</span><span class="nc">Compose</span><span class="p">([</span>
        <span class="n">albumentations</span><span class="p">.</span><span class="nc">Normalize</span><span class="p">(</span><span class="n">mean</span><span class="p">,</span> <span class="n">std</span><span class="p">,</span> <span class="n">max_pixel_value</span><span class="o">=</span><span class="mf">255.0</span><span class="p">,</span> <span class="n">always_apply</span><span class="o">=</span><span class="bp">True</span><span class="p">),</span>
    <span class="p">])</span>
    
    <span class="c1"># dataset and dataloader for test images
</span>    <span class="n">test_dataset</span> <span class="o">=</span> <span class="nc">MelanomaDataset</span><span class="p">(</span>
        <span class="n">image_paths</span><span class="o">=</span><span class="n">test_images</span><span class="p">,</span>
        <span class="n">targets</span><span class="o">=</span><span class="n">test_targets</span><span class="p">,</span>
        <span class="n">resize</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
        <span class="n">augmentations</span><span class="o">=</span><span class="n">test_aug</span>
    <span class="p">)</span>
    <span class="n">test_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="nc">DataLoader</span><span class="p">(</span>
        <span class="n">test_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">test_bs</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="mi">4</span>
    <span class="p">)</span>
    
    <span class="c1"># model in eval mode
</span>    <span class="n">model</span><span class="p">.</span><span class="nf">eval</span><span class="p">()</span>
    <span class="n">test_predictions</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">((</span><span class="nf">len</span><span class="p">(</span><span class="n">test_df</span><span class="p">),</span> <span class="mi">1</span><span class="p">))</span>
    
    <span class="n">tk0</span> <span class="o">=</span> <span class="nf">tqdm</span><span class="p">(</span><span class="n">test_loader</span><span class="p">,</span> <span class="n">total</span><span class="o">=</span><span class="nf">len</span><span class="p">(</span><span class="n">test_loader</span><span class="p">),</span> <span class="n">position</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">leave</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

    <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span>
        <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">data</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">tk0</span><span class="p">):</span>
            
            <span class="c1"># load tensor to GPU
</span>            <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">data</span><span class="p">.</span><span class="nf">items</span><span class="p">():</span>
                <span class="n">data</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
                
            <span class="n">batch_preds</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="o">**</span><span class="n">data</span><span class="p">)</span>
            
            <span class="n">start</span> <span class="o">=</span> <span class="n">idx</span> <span class="o">*</span> <span class="n">test_bs</span>
            <span class="n">end</span> <span class="o">=</span> <span class="n">start</span> <span class="o">+</span> <span class="nf">len</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="sh">'</span><span class="s">image</span><span class="sh">'</span><span class="p">])</span>
            <span class="n">test_predictions</span><span class="p">[</span><span class="n">start</span><span class="p">:</span><span class="n">end</span><span class="p">]</span> <span class="o">=</span> <span class="n">batch_preds</span><span class="p">.</span><span class="nf">cpu</span><span class="p">()</span>
    
    <span class="n">tk0</span><span class="p">.</span><span class="nf">close</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">test_predictions</span><span class="p">.</span><span class="nf">ravel</span><span class="p">()</span>

</code></pre></div></div> <p>Now, letâ€™s train each fold and save the best model.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">n_splits</span><span class="p">):</span>
    <span class="nf">train</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
</code></pre></div></div> <p>Great, now we are ready with our models so letâ€™s predict the targets on the test images:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">final_predictions</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">((</span><span class="nf">len</span><span class="p">(</span><span class="n">test_df</span><span class="p">),</span> <span class="mi">1</span><span class="p">)).</span><span class="nf">ravel</span><span class="p">()</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">n_splits</span><span class="p">):</span>
    <span class="n">final_predictions</span> <span class="o">+=</span> <span class="nf">predict</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>

<span class="n">final_predictions</span> <span class="o">/=</span> <span class="n">n_splits</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sample</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="sh">'</span><span class="s">./sample_submission.csv</span><span class="sh">'</span><span class="p">)</span>
<span class="n">sample</span><span class="p">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="sh">'</span><span class="s">target</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">final_predictions</span>
<span class="n">sample</span><span class="p">.</span><span class="nf">to_csv</span><span class="p">(</span><span class="sh">'</span><span class="s">submission.csv</span><span class="sh">'</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</code></pre></div></div> <h2 id="results">Results</h2> <p>Here, we had trained 2 models, SEResNeXt50_32x4d and the B2 variant of the EfficientNet model. Both models were trained using the loss functions BCE Loss and Focal Loss and the results are compared and tabulated as follows:</p> <table> <thead> <tr> <th>Model</th> <th>BCE Loss</th> <th>Focal Loss</th> </tr> </thead> <tbody> <tr> <td>SEResNeXt50_32x4d</td> <td>0.8934</td> <td>0.8762</td> </tr> <tr> <td>EfficientNet B2</td> <td>0.8972</td> <td>0.8921</td> </tr> <tr> <td>SEResNeXt50_32x4d + EfficientNet B2</td> <td>0.9019</td> <td>-</td> </tr> </tbody> </table> <p>In the 3rd case, we average out the predictions of both the models and assess the performance.</p> <h2 id="future-resources">Future Resources</h2> <p>Kaggle notebooks are a great place to learn and adapt to best practices of the experts. Here are the few kernels from the competition you can refer:</p> <ul> <li><a href="https://www.kaggle.com/nxrprime/siim-d3-eda-augmentations-and-resnext" target="_blank" rel="noopener noreferrer">SIIM: d3 EDA, Augmentations and ResNeXt</a></li> <li><a href="https://www.kaggle.com/datafan07/analysis-of-melanoma-metadata-and-effnet-ensemble" target="_blank" rel="noopener noreferrer">Analysis of Melanoma Metadata and EffNet Ensemble</a></li> <li><a href="https://www.kaggle.com/cdeotte/triple-stratified-kfold-with-tfrecords" target="_blank" rel="noopener noreferrer">Triple Stratified KFold with TFRecords</a></li> </ul> <div class="citations"> <d-cite key="skin_cancer_melanoma"> <d-cite key="siim_isic_kaggle"> <d-cite key="preprocessed_isic"> <d-cite key="roc_auc_google"> <d-cite key="lin_2022_focal_loss"> <d-cite key="Tan2019EfficientNetRM"> <d-cite key="EfficientNetRethinking"> <d-cite key="Hu2020SqueezeandExcitationN"> &lt;/div&gt; </d-cite></d-cite></d-cite></d-cite></d-cite></d-cite></d-cite></d-cite> </div> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> </div> <footer class="fixed-bottom"> <div class="container mt-0"> Â© Copyright 2025 Jay Gala. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>. Last updated: October 23, 2025. </div> </footer> <d-bibliography src="/assets/bibliography/2020-12-02-kaggle-melanoma-challenge.bib"></d-bibliography> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-BD3M6B4H2R"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-BD3M6B4H2R");</script> </body> </html>